{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"efb73a35","cell_type":"code","source":"import numpy as np\n\nimport pandas as pd\n\n\n\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\n\nimport plotly.graph_objects as go\n\nfrom plotly.offline import iplot\n\nfrom plotly.subplots import make_subplots\n\nimport plotly.figure_factory as ff\n\n\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.svm import SVC\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\n\n\n\n\nfrom sklearn.model_selection import train_test_split #split\n\nfrom sklearn.metrics import accuracy_score #metrics","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a29884e0","cell_type":"code","source":"\n\n# Read the CSV file with \";\" as the delimiter\n\ndf = pd.read_csv(\"bank.csv\", delimiter=\";\")\n\n\n\n# Remove double quotes from column names\n\ndf.columns = df.columns.str.replace('\"', '')\n\n\n\n# Remove double quotes from values\n\ndf = df.applymap(lambda x: x.replace('\"', '') if isinstance(x, str) else x)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"8da8475e","cell_type":"code","source":"df.head(5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"743a2f08","cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a33559f5","cell_type":"code","source":"df.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"b818c0d4","cell_type":"markdown","source":"EDA\n\n\n\nCategorical columns exploration\n\n\n\nIn the dataset we have both categorical and numerical columns. Let's look at the values of categorical columns first.","metadata":{}},{"id":"f4eea8b8","cell_type":"code","source":"cat_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month','poutcome']\n\n\n\n# Calculate the number of rows and columns needed for the grid\n\nnum_plots = len(cat_columns)\n\nnum_cols = 3\n\nnum_rows = -(-num_plots // num_cols)  # Ceiling division to ensure enough rows\n\n\n\nfig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 15))\n\n\n\n# Flatten the axes array if it's not already 1-dimensional\n\n# if not isinstance(axes, np.ndarray):\n\n#     axes = np.array([axes])\n\n\n\nfor i, column in enumerate(cat_columns):\n\n    row = i // num_cols\n\n    col = i % num_cols\n\n    sns.countplot(data=df, x=column, ax=axes[row, col])\n\n    axes[row, col].set_title(f'Count Plot of {column}')\n\n    axes[row, col].tick_params(axis='x', rotation=45)\n\n\n\n# Hide empty subplots if there are any\n\nfor i in range(num_plots, num_rows * num_cols):\n\n    row = i // num_cols\n\n    col = i % num_cols\n\n    fig.delaxes(axes[row, col])\n\n\n\nplt.tight_layout()\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"0cd7b7d0","cell_type":"markdown","source":"Numerical columns exploration\n\n\n\nNow let's look at the numerical columns' values. The most convenient way to look at the numerical values is plotting histograms.","metadata":{}},{"id":"d21a2cce","cell_type":"code","source":"plt.style.use('seaborn-whitegrid')\n\n\n\ndf.hist(bins=20, figsize=(14,10), color='#E10916')\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"e026d476","cell_type":"markdown","source":"We can see that some numerical columns have outliers (especially 'pdays'). we will analyse outliers later.","metadata":{}},{"id":"7f6c0e1f","cell_type":"markdown","source":"Analysis of the response column","metadata":{}},{"id":"826b8728","cell_type":"code","source":"value_counts = df['y'].value_counts()\n\n\n\nvalue_counts.plot.bar(title = 'Deposit value counts')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f88cb061","cell_type":"markdown","source":"Correlations","metadata":{}},{"id":"5a0b7eae","cell_type":"markdown","source":"Analysis by Occupation:\n\n\n\nNumber of Occupations: Management is the occupation that is more prevalent in this dataset.\n\n\n\nAge by Occupation: As expected, the retired are the ones who have the highest median age while student are the lowest.\n\n\n\nBalance by Occupation: Management and Retirees are the ones who have the highest balance in their accounts.","metadata":{}},{"id":"74369e66","cell_type":"code","source":"# Now let's see which occupation tended to have more balance in their accounts\n\n\n\nsuscribed_df = df.loc[df[\"y\"] == \"yes\"]\n\n\n\noccupations = df[\"job\"].unique().tolist()\n\n\n\n# Get the balances by jobs\n\nmanagement = suscribed_df[\"age\"].loc[suscribed_df[\"job\"] == \"management\"].values\n\ntechnician = suscribed_df[\"age\"].loc[suscribed_df[\"job\"] == \"technician\"].values\n\nservices = suscribed_df[\"age\"].loc[suscribed_df[\"job\"] == \"services\"].values\n\nretired = suscribed_df[\"age\"].loc[suscribed_df[\"job\"] == \"retired\"].values\n\nblue_collar = suscribed_df[\"age\"].loc[suscribed_df[\"job\"] == \"blue-collar\"].values\n\nunemployed = suscribed_df[\"age\"].loc[suscribed_df[\"job\"] == \"unemployed\"].values\n\nentrepreneur = suscribed_df[\"age\"].loc[suscribed_df[\"job\"] == \"entrepreneur\"].values\n\nhousemaid = suscribed_df[\"age\"].loc[suscribed_df[\"job\"] == \"housemaid\"].values\n\nself_employed = suscribed_df[\"age\"].loc[suscribed_df[\"job\"] == \"self-employed\"].values\n\nstudent = suscribed_df[\"age\"].loc[suscribed_df[\"job\"] == \"student\"].values\n\n\n\n\n\nages = [management, technician, services, retired, blue_collar, unemployed, \n\n         entrepreneur, housemaid, self_employed, student]\n\n\n\ncolors = ['rgba(93, 164, 214, 0.5)', 'rgba(255, 144, 14, 0.5)',\n\n          'rgba(44, 160, 101, 0.5)', 'rgba(255, 65, 54, 0.5)', \n\n          'rgba(207, 114, 255, 0.5)', 'rgba(127, 96, 0, 0.5)',\n\n         'rgba(229, 126, 56, 0.5)', 'rgba(229, 56, 56, 0.5)',\n\n         'rgba(174, 229, 56, 0.5)', 'rgba(229, 56, 56, 0.5)']\n\n\n\ntraces = []\n\n\n\nfor xd, yd, cls in zip(occupations, ages, colors):\n\n        traces.append(go.Box(\n\n            y=yd,\n\n            name=xd,\n\n            boxpoints='all',\n\n            jitter=0.5,\n\n            whiskerwidth=0.2,\n\n            fillcolor=cls,\n\n            marker=dict(\n\n                size=2,\n\n            ),\n\n            line=dict(width=1),\n\n        ))\n\n\n\nlayout = go.Layout(\n\n    title='Distribution of Ages by Occupation',\n\n    yaxis=dict(\n\n        autorange=True,\n\n        showgrid=True,\n\n        zeroline=True,\n\n        dtick=5,\n\n        gridcolor='rgb(255, 255, 255)',\n\n        gridwidth=1,\n\n        zerolinecolor='rgb(255, 255, 255)',\n\n        zerolinewidth=2,\n\n    ),\n\n    margin=dict(\n\n        l=40,\n\n        r=30,\n\n        b=80,\n\n        t=100,\n\n    ),\n\n    paper_bgcolor='rgb(224,255,246)',\n\n    plot_bgcolor='rgb(251,251,251)',\n\n    showlegend=False\n\n)\n\n\n\nfig = go.Figure(data=traces, layout=layout)\n\niplot(fig)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"9c58d240","cell_type":"code","source":"import plotly.graph_objects as go\n\nfrom plotly.subplots import make_subplots\n\nfrom plotly.offline import iplot\n\n\n\n\n\n# Define data traces for polar bar plot\n\ntrace1 = go.Barpolar(\n\n    r=negative,\n\n    theta=[\"blue-collar\", \"entrepreneur\", \"housemaid\", \"management\", \"retired\", \"self-employed\",\n\n         \"services\", \"student\", \"technician\", \"unemployed\"],\n\n    name='Negative Balance',\n\n    marker=dict(\n\n        color='rgb(246, 46, 46)'\n\n    )\n\n)\n\ntrace2 = go.Barpolar(\n\n    r=low,\n\n    theta=[\"blue-collar\", \"entrepreneur\", \"housemaid\", \"management\", \"retired\", \"self-employed\",\n\n         \"services\", \"student\", \"technician\", \"unemployed\"],\n\n    name='Low Balance',\n\n    marker=dict(\n\n        color='rgb(246, 97, 46)'\n\n    )\n\n)\n\ntrace3 = go.Barpolar(\n\n    r=middle,\n\n    theta=[\"blue-collar\", \"entrepreneur\", \"housemaid\", \"management\", \"retired\", \"self-employed\",\n\n         \"services\", \"student\", \"technician\", \"unemployed\"],\n\n    name='Middle Balance',\n\n    marker=dict(\n\n        color='rgb(246, 179, 46)'\n\n    )\n\n)\n\ntrace4 = go.Barpolar(\n\n    r=high,\n\n    theta=[\"blue-collar\", \"entrepreneur\", \"housemaid\", \"management\", \"retired\", \"self-employed\",\n\n         \"services\", \"student\", \"technician\", \"unemployed\"],\n\n    name='High Balance',\n\n    marker=dict(\n\n        color='rgb(46, 246, 78)'\n\n    )\n\n)\n\n\n\n# Create subplots for polar plots\n\nfig = make_subplots(rows=1, cols=1, subplot_titles=(\"Balance by Job Occupation\"))\n\n\n\n# Add traces to subplot\n\nfig.add_trace(trace1)\n\nfig.add_trace(trace2)\n\nfig.add_trace(trace3)\n\nfig.add_trace(trace4)\n\n\n\n# Update layout\n\nfig.update_layout(\n\n    title='Mean Balance in Account by Job Occupation',\n\n    polar=dict(\n\n        radialaxis=dict(\n\n            visible=True,\n\n            tickangle=45\n\n        )\n\n    )\n\n)\n\n\n\n# Plot figure\n\niplot(fig, filename='polar-bar-chart')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f33e3b27","cell_type":"markdown","source":"Marital Status\n\n\n\nWell in this analysis we didn't find any significant insights other than most divorced individuals are broke. No wonder since they have to split financial assets! Nevertheless, since no further insights have been found we will proceed to clustering marital status with education status. Let's see if we can find other groups of people in the sample population.","metadata":{}},{"id":"f75b9624","cell_type":"code","source":"# Distribution of Balances by Marital status\n\nsingle = df['balance'].loc[df['marital'] == 'single'].values\n\nmarried = df['balance'].loc[df['marital'] == 'married'].values\n\ndivorced = df['balance'].loc[df['marital'] == 'divorced'].values\n\n\n\n# Create Histogram traces for each marital status\n\nsingle_dist = go.Histogram(\n\n    x=single,\n\n    histnorm='density', \n\n    name='single',\n\n    marker=dict(\n\n        color='#6E6E6E'\n\n    )\n\n)\n\n\n\nmarried_dist = go.Histogram(\n\n    x=married,\n\n    histnorm='density', \n\n    name='married',\n\n    marker=dict(\n\n        color='#2E9AFE'\n\n    )\n\n)\n\n\n\ndivorced_dist = go.Histogram(\n\n    x=divorced,\n\n    histnorm='density', \n\n    name='divorced',\n\n    marker=dict(\n\n        color='#FA5858'\n\n    )\n\n)\n\n\n\n# Create subplots\n\nfig = make_subplots(rows=3, cols=1, subplot_titles=(\"Single\", \"Married\", \"Divorced\"))\n\n\n\n# Add traces to subplots\n\nfig.add_trace(single_dist, row=1, col=1)\n\nfig.add_trace(married_dist, row=2, col=1)\n\nfig.add_trace(divorced_dist, row=3, col=1)\n\n\n\n# Update layout\n\nfig.update_layout(\n\n    showlegend=False, \n\n    title=\"Price Distributions by Marital Status\",\n\n    height=1000, \n\n    width=800\n\n)\n\n\n\n# Plot figure\n\niplot(fig, filename='custom-sized-subplot-with-subplot-titles')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"64d6947f","cell_type":"code","source":"# Notice how divorced have a considerably low amount of balance.\n\n\n\nfig = ff.create_facet_grid(\n\n    df,\n\n    x='duration',\n\n    y='balance',\n\n    color_name='marital',\n\n    show_boxes=False,\n\n    marker={'size': 10, 'opacity': 1.0},\n\n    colormap={'single': 'rgb(165, 242, 242)', 'married': 'rgb(253, 174, 216)', 'divorced': 'rgba(201, 109, 59, 0.82)'}\n\n)\n\n\n\n# Plot figure\n\niplot(fig, filename='facet-custom-colormap')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d42547ee","cell_type":"markdown","source":"Clustering Marital Status and Education:\n\n\n\nMarital Status: As discussed previously, the impact of a divorce has a significant impact on the balance of the individual.\n\n\n\nEducation: The level of education also has a significant impact on the amount of balance a prospect has.\n\n\n\nLoans: Whether the prospect has a previous loan has a significant impact on the amount of balance he or she has.","metadata":{}},{"id":"c0ad9175","cell_type":"code","source":"df = df.drop(df.loc[df[\"education\"] == \"unknown\"].index)\n\ndf['education'].unique()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"215267b3","cell_type":"code","source":"df['marital/education'] = np.nan\n\nlst = [df]\n\n\n\nfor col in lst:\n\n    col.loc[(col['marital'] == 'single') & (df['education'] == 'primary'), 'marital/education'] = 'single/primary'\n\n    col.loc[(col['marital'] == 'married') & (df['education'] == 'primary'), 'marital/education'] = 'married/primary'\n\n    col.loc[(col['marital'] == 'divorced') & (df['education'] == 'primary'), 'marital/education'] = 'divorced/primary'\n\n    col.loc[(col['marital'] == 'single') & (df['education'] == 'secondary'), 'marital/education'] = 'single/secondary'\n\n    col.loc[(col['marital'] == 'married') & (df['education'] == 'secondary'), 'marital/education'] = 'married/secondary'\n\n    col.loc[(col['marital'] == 'divorced') & (df['education'] == 'secondary'), 'marital/education'] = 'divorced/secondary'\n\n    col.loc[(col['marital'] == 'single') & (df['education'] == 'tertiary'), 'marital/education'] = 'single/tertiary'\n\n    col.loc[(col['marital'] == 'married') & (df['education'] == 'tertiary'), 'marital/education'] = 'married/tertiary'\n\n    col.loc[(col['marital'] == 'divorced') & (df['education'] == 'tertiary'), 'marital/education'] = 'divorced/tertiary'\n\n    \n\n    \n\ndf.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"ea156c6f","cell_type":"code","source":"education_groups = df.groupby(['marital/education'], as_index=False)['balance'].median()\n\n\n\nfig = plt.figure(figsize=(12,8))\n\n\n\n\n\n\n\n\n\nsns.barplot(x=\"balance\", y=\"marital/education\", data=education_groups,\n\n            label=\"Total\", palette=\"RdBu\")\n\n\n\nplt.title('Median Balance by Educational/Marital Group', fontsize=16)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c02f6163","cell_type":"code","source":"# Let's see the group who had loans from the marital/education group\n\n\n\nloan_balance = df.groupby(['marital/education', 'loan'], as_index=False)['balance'].median()\n\n\n\n\n\nno_loan = loan_balance['balance'].loc[loan_balance['loan'] == 'no'].values\n\nhas_loan = loan_balance['balance'].loc[loan_balance['loan'] == 'yes'].values\n\n\n\n\n\nlabels = loan_balance['marital/education'].unique().tolist()\n\n\n\n\n\ntrace0 = go.Scatter(\n\n    x=no_loan,\n\n    y=labels,\n\n    mode='markers',\n\n    name='No Loan',\n\n    marker=dict(\n\n        color='rgb(175,238,238)',\n\n        line=dict(\n\n            color='rgb(0,139,139)',\n\n            width=1,\n\n        ),\n\n        symbol='circle',\n\n        size=16,\n\n    )\n\n)\n\ntrace1 = go.Scatter(\n\n    x=has_loan,\n\n    y=labels,\n\n    mode='markers',\n\n    name='Has a Previous Loan',\n\n    marker=dict(\n\n        color='rgb(250,128,114)',\n\n        line=dict(\n\n            color='rgb(178,34,34)',\n\n            width=1,\n\n        ),\n\n        symbol='circle',\n\n        size=16,\n\n    )\n\n)\n\n\n\ndata = [trace0, trace1]\n\nlayout = go.Layout(\n\n    title=\"The Impact of Loans to Married/Educational Clusters\",\n\n    xaxis=dict(\n\n        showgrid=False,\n\n        showline=True,\n\n        linecolor='rgb(102, 102, 102)',\n\n        titlefont=dict(\n\n            color='rgb(204, 204, 204)'\n\n        ),\n\n        tickfont=dict(\n\n            color='rgb(102, 102, 102)',\n\n        ),\n\n        showticklabels=False,\n\n        dtick=10,\n\n        ticks='outside',\n\n        tickcolor='rgb(102, 102, 102)',\n\n    ),\n\n    margin=dict(\n\n        l=140,\n\n        r=40,\n\n        b=50,\n\n        t=80\n\n    ),\n\n    legend=dict(\n\n        font=dict(\n\n            size=10,\n\n        ),\n\n        yanchor='middle',\n\n        xanchor='right',\n\n    ),\n\n    width=1000,\n\n    height=800,\n\n    paper_bgcolor='rgb(255,250,250)',\n\n    plot_bgcolor='rgb(255,255,255)',\n\n    hovermode='closest',\n\n)\n\nfig = go.Figure(data=data, layout=layout)\n\niplot(fig, filename='lowest-oecd-votes-cast')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"bbb01967","cell_type":"markdown","source":"Campaign Duration:\n\n\n\nCampaign Duration: Hmm, we see that duration has a high correlation with term deposits meaning the higher the duration, the more likely it is for a client to open a term deposit.\n\n\n\nAverage Campaign Duration: The average campaign duration is 374.76, let's see if clients that were above this average were more likely to open a term deposit.\n\n\n\nDuration Status: People who were above the duration status, were more likely to open a term deposit. 78% of the group that is above average in duration opened term deposits while those that were below average 32% opened term deposit accounts. This tells us that it will be a good idea to target individuals who are in the above average category.","metadata":{}},{"id":"81e8b838","cell_type":"code","source":"# Let's drop marital/education and balance status\n\n# Let's scale both numeric and categorical values\n\n# Then let's use a correlation matrix\n\n# With that we can determine if duration has influence on term deposits\n\n\n\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n\nfig = plt.figure(figsize=(12,8))\n\ndf['y'] = LabelEncoder().fit_transform(df['y'])\n\n\n\n\n\n\n\n# Separate both dataframes into \n\nnumeric_df = df.select_dtypes(exclude=\"object\")\n\n# categorical_df = df.select_dtypes(include=\"object\")\n\n\n\ncorr_numeric = numeric_df.corr()\n\n\n\n\n\nsns.heatmap(corr_numeric, cbar=True, cmap=\"RdBu_r\")\n\nplt.title(\"Correlation Matrix\", fontsize=16)\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"591ed1f1","cell_type":"code","source":"sns.set(rc={'figure.figsize':(11.7,8.27)})\n\nsns.set_style('whitegrid')\n\navg_duration = df['duration'].mean()\n\n\n\nlst = [df]\n\ndf[\"duration_status\"] = np.nan\n\n\n\nfor col in lst:\n\n    col.loc[col[\"duration\"] < avg_duration, \"duration_status\"] = \"below_average\"\n\n    col.loc[col[\"duration\"] > avg_duration, \"duration_status\"] = \"above_average\"\n\n    \n\npct_term = pd.crosstab(df['duration_status'], df['y']).apply(lambda r: round(r/r.sum(), 2) * 100, axis=1)\n\n\n\n\n\nax = pct_term.plot(kind='bar', stacked=False, cmap='RdBu')\n\nplt.title(\"The Impact of Duration \\n in Opening a Term Deposit\", fontsize=18)\n\nplt.xlabel(\"Duration Status\", fontsize=18);\n\nplt.ylabel(\"Percentage (%)\", fontsize=18)\n\n\n\nfor p in ax.patches:\n\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.02, p.get_height() * 1.02))\n\n    \n\n\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d973f670","cell_type":"markdown","source":"Pre Processing:\n\n\n\nOutlier Detection","metadata":{}},{"id":"9e46c58c","cell_type":"code","source":"from collections import Counter\n\ndef detect_outliers(data,features):\n\n    outlier_indices = []\n\n    for c in features:\n\n        # 1st quartile\n\n        Q1 = np.percentile(data[c],25)\n\n        # 3rd quartile\n\n        Q3 = np.percentile(data[c],75)\n\n        # IQR\n\n        IQR = Q3 - Q1\n\n        # Outlier step\n\n        outlier_step = IQR * 1.5\n\n        # detect outlier and their indeces\n\n        outlier_list_col = data[(data[c] < Q1 - outlier_step) | (data[c] > Q3 + outlier_step)].index\n\n        # store indeces\n\n        outlier_indices.extend(outlier_list_col)\n\n    \n\n    outlier_indices = Counter(outlier_indices)\n\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2)\n\n    \n\n    return multiple_outliers","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"1961e3fe","cell_type":"code","source":"outlier_indices = detect_outliers(df,['age','day','duration','campaign','previous'])\n\n\n\n# Check the outlier indices and print only the valid ones\n\nprint(\"Valid outlier indices:\")\n\nvalid_outlier_indices = []\n\nfor index in outlier_indices:\n\n    if index < len(df):\n\n        valid_outlier_indices.append(index)\n\n        print(index)\n\n    else:\n\n        print(f\"Index {index} is out of bounds.\")\n\n\n\n# Drop rows with valid outlier indices from the DataFrame\n\ndf = df.drop(valid_outlier_indices)\n\n\n\n# Print the cleaned DataFrame\n\nprint(\"DataFrame after dropping valid outlier indices:\")\n\nprint(df)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"2d79c73d","cell_type":"markdown","source":"Missing values","metadata":{}},{"id":"69c49220","cell_type":"code","source":"df.isna().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"cffd1775","cell_type":"markdown","source":"I do not include the Duration column in the dataset, as it is unknown data at the time of the prediction.","metadata":{}},{"id":"daa3cdb3","cell_type":"code","source":"df=df.drop(['duration'],axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"6caedb0a","cell_type":"markdown","source":"One-Hot Encoding","metadata":{}},{"id":"d83ee3fa","cell_type":"code","source":"df.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"1f091968","cell_type":"code","source":"columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n\n\n\ndf = pd.get_dummies(df, columns=columns).mul(1)\n\ndf.head()","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"id":"05175c94","cell_type":"markdown","source":"The pdays data indicates how many times the customer has been contacted before.\n\n\n\nUpdated as follows:\n\n\n\nif the pdays = 0, it indicates that it has not been contacted before\n\n\n\nif the pdays = 1, it indicates that it was contacted earlier","metadata":{}},{"id":"915dc54d","cell_type":"code","source":"def pdayswork(pdays):\n\n    if(pdays == -1):\n\n        return(0)\n\n    elif(pdays >= 0):\n\n        return(1)\n\ndf['pdays2'] = df['pdays'].apply(pdayswork)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"7bb7c6fb","cell_type":"markdown","source":"our target column, whose data type is object, turned into numerical values. And new target column name is depositNew. Also as this is a classification problem, the target column can remain as an object. But I chose to convert it to int data type.","metadata":{}},{"id":"b16b02f2","cell_type":"code","source":"def deposit1(y):\n\n    if(y=='yes'):\n\n        return(1)\n\n    elif(y=='no'):\n\n        return(0)\n\ndf['deposit'] = df['y'].apply(deposit1)\n\n\n\ndf=df.drop(['y'],axis=1)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c09734e2","cell_type":"markdown","source":"Data Normalization","metadata":{}},{"id":"d9f3bad7","cell_type":"code","source":"df.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"3a012cd5","cell_type":"code","source":"df = df.drop(['marital/education'], axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"bb28b08c","cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nX = df.iloc[:, 0:51]\n\nY = df.iloc[:, 51]\n\nnd = StandardScaler()\n\nnd.fit(X)\n\nX =nd.transform(X)\n\nprint(X)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"b1f69d3a","cell_type":"code","source":"Model Building","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"e8d433e5","cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import cohen_kappa_score\n\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.metrics import confusion_matrix\n\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\nfrom sklearn.metrics import f1_score\n\nX = df.iloc[:, 0:51]\n\nY = df.iloc[:, 51]\n\nX_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.2, random_state = 100)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"06000a27","cell_type":"code","source":"svm_classifier = SVC(random_state=3432, C=0.5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"20ed0af7","cell_type":"code","source":"svm_classifier.fit(X_train, y_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d4661f89","cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n\n# Predicting Test Set\n\ny_pred =svm_classifier.predict(X_test)\n\n\n\nacc = accuracy_score(y_test, y_pred)\n\nprec = precision_score(y_test, y_pred)\n\nrec = recall_score(y_test, y_pred)\n\nf1 = f1_score(y_test, y_pred)\n\n\n\nmodel_results = pd.DataFrame([['SVM (Linear)', acc, prec, rec, f1]],\n\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n\n\n\n# results = results.append(model_results, ignore_index = True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"85e4aba4","cell_type":"code","source":"clf = RandomForestClassifier(n_estimators=100, max_depth=12,random_state=50)\n\n\n\nclf.fit(X_train,y_train)\n\n\n\nprediction = clf.predict(X_test)\n\n\n\nacc = accuracy_score(y_test,prediction)*100\n\nprint(\"Random Forest accuracy:\",acc)\n\n# accuracies['Random Forest']=acc\n\n\n\nf1=f1_score(y_test,prediction)*100\n\nprint(\"F1-Score: \",f1)\n\nf1scores['Random Forest']=f1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"0bc7a698","cell_type":"code","source":"knn= KNeighborsClassifier(n_neighbors = 4)\n\nknn.fit(X_train, y_train)\n\nprediction=knn.predict(X_test)\n\n\n\nacc = accuracy_score(y_test,prediction)*100\n\nprint(\"Knn accuracy:\",acc)\n\naccuracies['KNN']=acc\n\n\n\nf1=f1_score(y_test,prediction)*100\n\nprint(\"F1-Score: \",f1)\n\nf1scores['KNN']=f1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"330ce8cd","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}